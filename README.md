***

# Оглавление
- [Задание №1](#задание-№1)
  - [Клонирование репозитория](#клонирование-репозитория)
  - [Настройка jupyter notebook](#настройка-jupyter-notebook)
  - [Настройка jupyterhub server](#настройка-jupyterhub-server)
  - [Настройка PostgeSQL](#настройка-postgesql)
  - [Ответы на вопросы](#ответы-на-вопросы)
- [Задание №2](#задание-№2)
  - [1.Используемые инструменты для мониторинга, сбора метрик и визуализации.](#конфигурация-системы-мониторинга-на-базе-prometheus-grafana-loki)
  - [2. Добавление сервисов в Docker Compose](#2-Добавление-сервисов-в-Docker-Compose)
  - [3. Дашборды](#3-Дашборды)
    - [3.1 Дашборд Активности пользователей и Размера тетрадок Jupyterhub.](#31-Дашборд-Активности-пользователей-и-Размера-тетрадок-Jupyterhub)
    - [3.2 Дашборд размера таблиц в PostgreSQL.](#32-Дашборд-размера-таблиц-в-PostgreSQL)
    - [3.4 Дашборд используемых ресурсов контейнерами](#34-Дашборд-используемых-ресурсов-контейнерами)
  - [4. Алерты](#4-Алерты)
    - [4.1 Алерт использования CPU на 80%](#41-Алерт-использования-CPU-на-80)
    - [4.2 Алерт входа по SSH на сервер.](#42-Алерт-входа-по-SSH-на-сервер)
  - [Итог](#Итог)

***

# Задание №1
***
Необходимо:

1. Развернуть jupyterhub и Postgres.

2. Зарегестрировать 3 пользователей в jupyterhub.

3. Настроить соеденение Postgres с jupyterhub с помощью библиотеки psycopg2


Контрольные вопросы:   
1. На каком порту разворачивается юпитер?
2. Есть ли у пользователей пароли или их кто-то задает?
3. В случае добавления пользователя - как это сделать?
4. В случае увольнения пользователя - как его убрать?
5. В каком виде и где хранятся пароли пользователей?
6. Как смотреть активен ли пользователь? Например он уволился, но нам не сказали, а учетка жива
7. И как посмотреть активность пользователя - сколько его ноутбуки поджирают места
***


## Клонирование репозитория
Предварительно нужно установить  [ubuntu server, docker и docker-compose](./docs/install_docker.md)  

### Запуск приложений
```bash
cd ~
git clone https://github.com/vokulovskiy/firetech_41.git 
cd firetech_41
## Запускаем приложения
docker compose up --build -d
```
## Настройка jupyter notebook

В качестве тетрадки для пользователя выбран минимальный базовый образ jupyter/minimal-notebook. Из него собирается кастомная тетрадка с предустановленными библиотеками: numpy, pandas, psycopg2-binary и т.п.

В репозитории https://hub.docker.com/u/jupyter хранится много готовых образов с предустановленными различными фреймворками для НС. При развертывании на реальный сервер нужно выбрать образ под требования DS
```bash
# Сборка образа для ноутбуков
cd configs
docker build -f Dockerfile.notebook -t pattern_notebook:v1 .
cd ..
```
***
## Настройка jupyterhub server

Был взят базовый образ jupyterhub и на его основе собирается кастомный образ т.к. настройки хранятся в файле [jupyterhub_config.py](./configs/jupyterhub_config.py) и при его изменении нужно пересобирать образ. В jupyterhub добавлены следующие библиотеки:

**1. ``oauthenticator``** - 
Библиотека для аутентификации пользователей через протокол OAuth2.
Позволяет пользователям авторизовываться через внешние провайдеры (например, GitHub, Google, Microsoft), что упрощает управление учётными записями.

**3. `dockerspawner`** - 
Расширение JupyterHub для запуска отдельных Docker-контейнеров для каждого пользователя.
Обеспечивает полную изоляцию рабочих сред пользователей, что особенно важно в многопользовательских системах.

**4. `jupyterhub-nativeauthenticator`** - 
Библиотека для локальной аутентификации на основе имени пользователя и пароля.
Полезна для случаев, когда требуется использовать локальные учётные записи без интеграции с внешними провайдерами.

**5. `prometheus-client`** - 
Библиотека для интеграции с системой мониторинга Prometheus.
Помогает администраторам собирать метрики производительности и состояния системы, что необходимо для оптимизации работы JupyterHub.
***

Аутентификация :
- `c.JupyterHub.authenticator_class` = `NativeAuthenticator`: Используется локальный аутентификатор `NativeAuthenticator`, который позволяет пользователям регистрироваться через форму с логином и паролем.

- `c.NativeAuthenticator.open_signup` = `False`: Запрещает новым пользователям самостоятельно регистрироваться на платформе.

- `c.JupyterHub.spawner_class` = `DockerSpawner`: Используется спонер DockerSpawner, который запускает отдельный Docker-контейнер для каждого пользователя.

***
## Настройка PostgeSQL
Взят оффициальный образ postgres:17   
Для первичного доступа в Postgres данные хранятся в файле [.env](./.env), в дальнейшем они так же используются для postgres-exporter.
***
## Ответы на вопросы
1. На каком порту разворачивается юпитер?   
  `В данной конфигурации JupyterHub разворачивается па 8000 порту.`
2. Есть ли у пользователей пароли или их кто-то задает?   
  `Пользователь сам задает пароль при регистрации на первом входе в JupyterHub http://your-domain:8000/hub/signup`   
  ![](screens/Jupyter_sign_up.JPG)
  `В дальнейшем администратор может поменять пароль на странице http://your-domain:8000/hub/authorize`
  ![](screens/Jupyter_admin_autorize.JPG)
3. В случае добавления пользователя - как это сделать?
  `Администратор добавляет пользователей на странице http://your-domain:8000/hub/admin#/`
  ![](screens/Jupyter_admin_users.JPG)
4. В случае увольнения пользователя - как его убрать?  
  `Администратор удаляет пользователей на странице http://your-domain:8000/hub/admin#/edit-user`
5. В каком виде и где хранятся пароли пользователей?   
  `Пароли хранятся в зашифрованном виде в /data/jupyterhub.sqlite`
6. Как смотреть активен ли пользователь? Например он уволился, но нам не сказали, а учетка жива.   
  `Администратор может посмотреть активность пользователей на странице http://your-domain:8000/hub/admin#/ колонка Last Activity`
7. И как посмотреть сколько его ноутбуки поджирают места  
  `Каждый ноут пользователя - это отдельный докер контейнер. Статистику по ним можно посмотреть в графане, или командой`  
  ```bash
  docker stats --no-stream
  ```
 ![](screens/Jupyter_stats.JPG) 
8. [Как подключиться к тетрадке в JupyterHub через Visual Studio Code](docs\Connect_VSC.md) 

## Заключение
В ходе выполнения домашнего задания мы научились разворачивать jupytehub c возможностью регистрации новых пользователей, а так же подключаться через Jupyterhub к базе данных Postgres и манипулировать данными.


# Задание №2

***
## Техническое задание

### Настроить Мониторинг.

- Дашборд активности пользователей в юпитер (количество операций в день)

- Дашборд по топовым тетрадкам (сколько подъедают)

- Дашборд топовых таблиц в постресе с их владельцами

### Настроить алерты.

- Настроить алерт при заходе пользователя на сервер по ssh на почту.

- Настроить почтовый алерт при потребление общим количеством контейнеров мощности более чем на 80 % - алертить.

***
## Конфигурация системы мониторинга на базе Prometheus, Grafana, Loki.

**Для сбора метрик** и их экспорта, а так же визуализации будем использовать следующие образы:

`Prometheus` - Основной инструмент для сбора и хранения метрик от различных источников.

`Grafana` - Платформа для визуализации данных и создания дашбордов. Поддерживает множество источников данных, включая Prometheus.

`Loki` - Основной инструмент для сбора и хранения логов от различных источников. Кроме всего прочего будет использоваться для алерта, при заходе пользователя на сервер по ssh.

`postgres-exporter` - Exporter для сбора метрик PostgreSQL. Преобразует статистику PostgreSQL в формат, понятный Prometheus. В том числе доступен сбор метрик по кастомному SQL запросу.

`cadvisor` - Exporter потребления ресурсов (CPU, память, диск, сеть) для всех контейнеров на хост-машине.

`Node Exporter` — это экспортер Prometheus для сбора данных о состоянии сервера с подключаемыми коллекторами метрик. Он позволяет измерять различные ресурсы машины, такие как использование памяти, диска и процессора.

`Promtail`  - это агент, который собирает журналы, превращает их в потоки, добавляя метки, а после отправляет всё в Loki с помощью HTTP API.

**Для алертов**

`alertmanager` - Система управления оповещениями для Prometheus. Обрабатывает алерты, отправляемые Prometheus, и доставляет их через различные каналы (email, telegram и др.).

***
## 2. Добавление сервисов в Docker Compose

1. Для создания полнофункциональной системы мониторинга допишем все необходимые образы в **[Docker-compose](docker-compose.yml)** 

2. Для корректной работы `Prometheus` необходимо определить все `scrape jobs` в файле **[prometheus.yml](configs/prometheus.yml)**. Этот файл определяет, какие сервисы и эндпоинты Prometheus должен мониторить для сбора метрик. 

3. Для работы с образом **`postgres-exporter`** требуется настроить файл **[queries.yaml](configs/queries.yaml)**. Этот файл содержит конфигурацию пользовательских метрик и SQL-запросы, которые будут выполняться для сбора данных из базы данных PostgreSQL. 


4. Для `alertmanager` необходимо настроить файлы **[alertmanager.yml](configs/alertmanager.yml)** и **[alert.rules.yml](configs/alert.rules.yml)**

- `alertmanager.yml` : Отвечает за управление и доставку алертов (кому и как отправлять уведомления).

- `alert.rules.yml` : Определяет условия для генерации алертов (когда и почему срабатывает алерт).


Соберем наш образ командой  `Docker-compose up -d`  
И убедимся, что все работает. `docker ps`


Проверьте работу: 

- `Prometheus` по адресу `http://localhost:9090`

- `Grafana` по адресу `http://localhost:3000`

Чтобы войти в `Grafana` по умолчанию используется ЛОГИН `admin` ПАРОЛЬ `admin` после система предложит вам изменить пароль (если при сборке образа вы не задали другие учетные данные)
![2025-02-24_11-56-12](https://github.com/user-attachments/assets/3ab2ec7e-14e9-44a8-a485-b30b0319de57)


Проверим работу всех exporter в `prometheus`.

`http://localhost:9090/targets`

Убедимся, что `State` у всех `exporter` имеет статус UP (значит все `exporter` передают наши метрики в `prometheus`)

![2025-02-23_18-27-32](https://github.com/user-attachments/assets/8e433c92-d37c-484c-8c7a-1a70c54e23a6)

Переходим в `http://localhost:9090/alerts` и проверяем добавился ли наш алерт 
![2025-02-23_19-16-00](https://github.com/user-attachments/assets/f48c656f-2c6f-4d11-9bce-6cd5ff576261)


Добавим источник данных в `Grafana` заходим в раздел `Data sources` и добавляем  `prometheus` в графе `Connection` прописываем `host` и `port`
![2025-02-23_18-13-37](https://github.com/user-attachments/assets/54177072-c343-412d-853e-1e9d31f0dc6d)
наши контейнеры находятся в общей сети `jupyter-network` поэтому обращаемся по названию конрейнера и порту(если контейнеры находятся в разных сетях обращаться необходимо по IP либо localhost и внешнему порту который вы прокинули наружу).

Добавим дашборд для проверки работоспособности:

1. Выберем раздел `dashboards`
2. Add visualization (Если хотеите импортировать какой то определенный дашборд шелкаем `Import a dashboard` и импортируем необходимы дашборд)
![2025-02-24_12-10-38](https://github.com/user-attachments/assets/ca8e9add-ed83-4af2-b231-185a79ee395a)

Визуализация метрики:

1. Выбираем метрику.
2. Выбираем `Legend` подпись для графиков
3. Установим необходимую единицу измерения
![2025-02-24_12-15-12](https://github.com/user-attachments/assets/2f38bb9d-f716-448d-8153-49341a42f01d)

## 3. Дашборды
### 3.1 Дашборд Активности пользователей и Размера тетрадок Jupyterhub.

Метрики:
- `jupyterhub_total_users` - количество зарегистрированых пользователей
- `jupyterhub_active_users{period="24h"}` - количество активных пользователей за 24 часа
- `jupyterhub_running_servers` - количество запушенных серверов
- `sum(jupyterhub_request_duration_seconds_count)` - количество запросов
- `jupyterhub_notebook_file_size_bytes` - кастомная метрика [exporter](notebook_metrics/jupyterhub_notebook_files_metrics.py) которая передает размеры тетрадок jupyterhub
![2025-02-23_18-56-03](https://github.com/user-attachments/assets/81e2b3ae-ae0b-46a5-91f7-cdb752cb10c0)

### 3.2 Дашборд размера таблиц в PostgreSQL.

Гистограмы отражают топ 10 самых больших таблиц и их пользователей в моем случае таблицы 4 поэтому показано только 4.

На графике отражается динамика добавления данных в таблицы, когда и сколько килобайт данных добавлены в таблицу.

Метрика:
- `table_sizes_size_bytes` - была определена внутри **[queries.yaml](https://github.com/Zubaev/jupyterhub_docker_postgres/blob/main/postgres-exporter/queries.yaml)** 

![2025-02-23_18-35-23](https://github.com/user-attachments/assets/816040f1-cc21-482e-b293-d107974da18e)

### 3.4 Дашборд используемых ресурсов контейнерами 
![2025-02-23_18-41-34](https://github.com/user-attachments/assets/73330863-d342-48e9-ad1f-38a83d863114)

## 4. Алерты

### 4.1 Алерт использования CPU на 80%

Проверим приходят ли оповещения, для проверки работоспособности я временно снизил парог чтобы при загрузке 30% приходил алерт, все работает!)
![2025-02-23_19-18-26](https://github.com/user-attachments/assets/2ac0fd8d-b1ef-40bc-8785-a40e01720913)

### 4.2 Алерт входа по SSH на сервер.

1. установим необходимые зависимости
```
sudo apt-get install postfix mailutils -y
```
2. Настройка Postfix
Создайте файл паролей:
```
sudo nano /etc/postfix/sasl_passwd
```

Перед настройкой Postfix необходимо иметь пароль приложения. Это делается в разделе безопасности вашей учетной записи почты.

`'smtp.yandex.ru:587'` - Адрес SMTP-сервера и порт для отправки писем

<img width="568" alt="Снимок экрана 2025-02-24 135449" src="https://github.com/user-attachments/assets/69fc55ed-a9be-4f90-bf06-bf948a371ab8" />


Сохраните изменения, а затем измените разрешения файла, так чтобы его мог просматривать только пользователь root:
```
sudo chmod 600 /etc/postfix/sasl_passwd  
```

Откройте основной файл конфигурации Postfix:
```
sudo nano /etc/postfix/main.cf 
```

В файле main.cf найдите параметр relayhost и измените строку на:
```bash
relayhost = [smtp.yandex.ru]:587 #если вы используете yandex
```

Ниже этой строки добавьте следующее:
```bash
relayhost = [smtp.yandex.ru]:587

smtp_use_tls = yes
smtp_sasl_auth_enable = yes
smtp_sasl_security_options =
smtp_sasl_password_maps = hash:/etc/postfix/sasl_passwd
smtp_tls_CAfile = /etc/ssl/certs/ca-certificates.crt

mynetworks = [::ffff:127.0.0.0]/104 [::1]/128 #эти строки неоходимо заменить
mailbox_size_limit = 0 #эти строки неоходимо заменить
recipient_delimiter = + #эти строки неоходимо заменить
inet_interfaces = all #эти строки неоходимо заменить
inet_protocols = ipv4 #эти строки неоходимо заменить
```

Далее нужно скомпилировать и хешировать содержимое файла sasl_password, который мы создали ранее, с помощью команды:
```
sudo postmap /etc/postfix/sasl_passwd
```
Перезапустите Postfix:

```
sudo systemctl restart postfix  
```

Включите Postfix для запуска при старте:

```
sudo systemctl enable postfix
```

3. Создание оповещения о входе по SSH

Введите команду:
```
sudo nano /etc/profile
```

В конце файла добавьте следующее:

```bash
if [ -n "$SSH_CLIENT" ]; then
    TEXT="$(date): ssh login to ${USER}@$(hostname -f)"
    TEXT="$TEXT from $(echo $SSH_CLIENT | awk '{print $1}')"
    echo "$TEXT" | mail -s "ssh login" magazubaev92@gmail.com -a "From:magazubaev92@yandex.ru"
fi

```
`magazubaev92@gmail.com` - почта получателя
`magazubaev92@yandex.ru` - почта отправителя

Проверяем работоспособность
![2025-02-24_14-13-08](https://github.com/user-attachments/assets/d8743948-12eb-4c5e-a92e-d7caa1ba4f7b)

# Итог

В рамках выполнения второго домашнего задания мы приобрели практические навыки в настройке комплексной системы мониторинга, основанной на следующих ключевых компонентах:

`Prometheus` : Изучили основы конфигурации `Prometheus` для сбора и хранения метрик различных сервисов. Настроили `scrape jobs` для сбора данных с разных источников.

`Grafana` : Научились создавать дашборды для визуализации собранных метрик, что позволяет эффективно анализировать состояние системы и выявлять тренды.

Система оповещений : Реализовали настройку `Alertmanager` для автоматического реагирования на критические ситуации. Настроили правила алертов, которые позволяют своевременно получать уведомления о проблемах на почту.
В результате работы мы создали полноценную инфраструктуру мониторинга, способную обеспечивать прозрачность производительности системы, оперативное обнаружение проблем и автоматическое информирование ответственных лиц о чрезвычайных ситуациях.
